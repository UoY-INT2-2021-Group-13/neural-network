{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, Lambda\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "#Debug parameters:\n",
    "PRINT_EPOCH_PROGRESS_MESSAGES = False\n",
    "  #whether to print \"Processing: 10000/50000\" messages while processing epochs\n",
    "PRINT_EPOCH_PROCESSING_TIME = True\n",
    "  #whether to print \"Processed in: 6.17 seconds\" messages after processing an epoch\n",
    "EPOCH_PRINT_STRIDE = 1\n",
    "  #number of epochs to skip printing (eg 10 will only print every 10th epoch)\n",
    "  #last epoch is always printed\n",
    "ALWAYS_PRINT_CLASS_ACCURACY = True\n",
    "  #whether to print the accuracy per class (\"Accuracy for dog: 20%\") for every epoch\n",
    "  #last epoch is always printed with class accuracy\n",
    "\n",
    "#Hyper-parameters:\n",
    "EPOCHS = 100\n",
    "  #number of iterations - a simple network will be around ~5 seconds per epoch, a bigger one can be ~20\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 4\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "TRANSFORM = Compose(\n",
    "    [ToTensor(),\n",
    "     Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #normalizing the data from [0,1] to [-1,1], which makes the net happier for reasons i don't understand\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: ' + device)\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='datasets',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=TRANSFORM\n",
    ")\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='datasets',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=TRANSFORM\n",
    ")\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') #used for printing results by class\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 5),\n",
    "            #take 5x5 convolutions to turn the 3 input colour channels into 8 output channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #squish a channel to half size by taking the highest value in every 2x2 block\n",
    "            #this is done to keep the processing small - most of these values are very similar\n",
    "            nn.Conv2d(8, 32, 5),\n",
    "            #turn those 8 channels into 32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #squish again!\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(32 * 5 * 5, 200),\n",
    "            #take the 32 channels (now 5x5 in size due to squishing and edges being lost from no padding)\n",
    "            #and make a fullly connected neural net to make it into a single flat matrix\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100),\n",
    "            #do another linear step so the network can make some clever deductions\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "            #finally reduce to 10 outputs - these are our output classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "          #take the [4, 32, 5, 5] tensor and resize it to be a [4, 32*5*5] tensor\n",
    "          #so we can do linear stuffs with it\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, do_print=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch_num, (inputs, labels) in enumerate(dataloader):\n",
    "        #move tensors to correct device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Compute prediction and loss\n",
    "        prediction = model(inputs)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "        # Backpropagate and optimize model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print something every 100 batches to let us know it's not dead\n",
    "        if PRINT_EPOCH_PROGRESS_MESSAGES and do_print and batch_num % 100 == 0:\n",
    "            current = batch_num * len(inputs)\n",
    "            print(\"Processed: \" + str(current) + \"/\" + str(size))\n",
    "\n",
    "def test(dataloader, model, loss_fn, do_classes=False):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    #init dictionary of classes\n",
    "    total_correct_class = {}\n",
    "    for classname in classes:\n",
    "        total_correct_class[classname] = 0\n",
    "\n",
    "    with torch.no_grad(): #disable gradients when not training (makes it faster)\n",
    "        for inputs, labels in dataloader:\n",
    "            #move tensors to correct device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #calculate test error\n",
    "            prediction = model(inputs)\n",
    "            total_loss += loss_fn(prediction, labels).item()\n",
    "            total_correct += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            if do_classes:\n",
    "                #isolate label predictions:\n",
    "                _, label_predictions = torch.max(prediction, 1)\n",
    "                #need to process these individually, can't be handled as a batch\n",
    "                for label, prediction in zip(labels, label_predictions):\n",
    "                    if label == prediction:\n",
    "                        total_correct_class[classes[label]] += 1\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    class_size = size // 10\n",
    "    if do_classes:\n",
    "        for classname, correct in total_correct_class.items():\n",
    "            percentage_correct = round(100 * correct / class_size, 4)\n",
    "            print(\"Accuracy for \" + classname + \": \" + str(percentage_correct) + \"%\")\n",
    "\n",
    "    average_loss = round(total_loss / size, 5)\n",
    "    percentage_correct = round(100 * total_correct / size, 4)\n",
    "    print(\"Accuracy: \" + str(percentage_correct) + \"%\")\n",
    "    print(\"Average Loss: \" + str(average_loss))\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "previous_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    #only print if this matches an epoch print stride, or is the last epoch\n",
    "    do_print = epoch % EPOCH_PRINT_STRIDE == 0 or epoch == EPOCHS-1\n",
    "    #likewise for printing class accuracies\n",
    "    do_classes = ALWAYS_PRINT_CLASS_ACCURACY or epoch == EPOCHS-1\n",
    "    if do_print:\n",
    "      print(\"-----------------------------\")\n",
    "      print(\"Epoch \" + str(epoch+1))\n",
    "    train(train_dataloader, model, LOSS_FUNCTION, optimizer, do_print)\n",
    "    #only calculate results if printing them:\n",
    "    if do_print:\n",
    "      test(test_dataloader, model, LOSS_FUNCTION, do_classes)\n",
    "      if PRINT_EPOCH_PROCESSING_TIME:\n",
    "        print(\"Processed in: \" + str(round(time.time() - previous_time,2)) + \" seconds\")\n",
    "        previous_time = time.time()\n",
    "      \n",
    "print(\"finished :D\")"
   ]
  }
 ]
}